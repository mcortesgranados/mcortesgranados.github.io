<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Stacking Example</title>
    <!-- Include necessary CSS or styling if needed -->
</head>
<body>

<h1>Stacking Example</h1>

<p>This is a simple example of stacking using Python and the scikit-learn library.</p>

<h2>Stacking Overview</h2>

<p>Stacking is an ensemble learning technique that combines multiple base models to create a meta-model, often referred to as a blender or meta-classifier. It involves training several diverse base models on the training data and then using a meta-model to make predictions based on the outputs of these base models. Stacking can be effective in improving predictive performance by leveraging the strengths of different models.</p>

<p>Key concepts of stacking:</p>

<ul>
    <li><b>Base Models:</b> Individual models trained on the training data.</li>
    <li><b>Meta-Model:</b> A higher-level model that combines the predictions of base models.</li>
    <li><b>Diversity:</b> Ensuring diversity among base models to capture different aspects of the data.</li>
    <li><b>Training and Prediction:</b> Training base models, using them to make predictions, and then training the meta-model on these predictions.</li>
</ul>

<p>Python Source Code:</p>

<pre><code># Import necessary libraries
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.datasets import make_classification
from sklearn.ensemble import StackingClassifier

# Generate synthetic data for classification
X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_clusters_per_class=2, random_state=42)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define base models
base_models = [
    ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),
    ('gb', GradientBoostingClassifier(n_estimators=50, random_state=42))
]

# Define the meta-model
meta_model = LogisticRegression()

# Create the stacking classifier
stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=meta_model)

# Train the stacking classifier on the training data
stacking_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred = stacking_classifier.predict(X_test)

# Evaluate the performance of the stacking classifier
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy of Stacking Classifier: {accuracy:.2f}')
</code></pre>

<p>Explanation:</p>

<ul>
    <li><b>Import Libraries:</b> Import necessary Python libraries, including scikit-learn for ensemble learning.</li>
    <li><b>Generate Synthetic Data:</b> Generate synthetic data for classification.</li>
    <li><b>Split Data:</b> Split the data into training and testing sets.</li>
    <li><b>Define Base Models:</b> Define a list of base models (Random Forest and Gradient Boosting).</li>
    <li><b>Define Meta-Model:</b> Define the meta-model (Logistic Regression) that combines the outputs of base models.</li>
    <li><b>Create Stacking Classifier:</b> Create a Stacking Classifier using the base models and meta-model.</li>
    <li><b>Train and Predict:</b> Train the stacking classifier on the training data and make predictions on the test set.</li>
    <li><b>Evaluate Performance:</b> Evaluate the performance of the stacking classifier using accuracy.</li>
</ul>

<!-- Include necessary JavaScript libraries if needed -->

</body>
</html>
