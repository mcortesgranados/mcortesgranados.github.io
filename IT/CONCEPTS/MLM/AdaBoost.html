<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>AdaBoost Example</title>
    <!-- Include necessary CSS or styling if needed -->
    <link href="../estilos.css" rel="stylesheet" type="text/css">
</head>
<body class="texto8_1">

<h1>AdaBoost Example</h1>

<p>This is a simple example of AdaBoost using Python and scikit-learn.</p>

<h2>AdaBoost Overview</h2>

<p>AdaBoost (Adaptive Boosting) is an ensemble learning method that combines the predictions of multiple weak learners to create a strong learner. A weak learner is a model that performs slightly better than random chance. AdaBoost assigns weights to each instance in the dataset and focuses on the mistakes made by the weak learners. It then assigns higher weights to misclassified instances, enabling subsequent weak learners to focus on correcting these mistakes. The final prediction is a weighted sum of the weak learners' predictions.</p>

<p>Key concepts of AdaBoost:</p>

<ul>
    <li><b>Weak Learners:</b> Simple models that perform slightly better than random chance.</li>
    <li><b>Instance Weights:</b> Each instance in the dataset is assigned a weight, and these weights are updated during training.</li>
    <li><b>Focus on Mistakes:</b> AdaBoost gives higher importance to instances that are misclassified by the weak learners.</li>
    <li><b>Weighted Sum:</b> The final prediction is a weighted sum of the weak learners' predictions.</li>
    <li><b>Sequential Training:</b> Weak learners are trained sequentially, and each subsequent learner focuses on correcting the mistakes of the previous ones.</li>
</ul>

<p>AdaBoost is known for its simplicity and effectiveness, and it is often used with decision trees as weak learners.</p>

<p>Python Source Code:</p>

<pre><code># Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix

# Generate synthetic classification data
np.random.seed(42)
X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_clusters_per_class=2, random_state=42)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build an AdaBoost model with decision tree as base estimator
base_estimator = DecisionTreeClassifier(max_depth=1)
adaboost = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50, random_state=42)
adaboost.fit(X_train, y_train)

# Make predictions on the test set
y_pred = adaboost.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)

print(f'Accuracy: {accuracy}')
print(f'Confusion Matrix:\n{conf_matrix}')

# Plot the results
plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='viridis', marker='o', edgecolors='black', label='Actual Data')
plt.title('AdaBoost Example')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.show()
</code></pre>

<p>Explanation:</p>

<ul>
    <li><b>Import Libraries:</b> Import necessary Python libraries, including NumPy for numerical operations, Matplotlib for plotting, and scikit-learn for dataset generation and AdaBoost.</li>
    <li><b>Generate Synthetic Data:</b> Create synthetic classification data with 20 features using the <code>make_classification</code> function from scikit-learn.</li>
    <li><b>Split Data:</b> Split the data into training and testing sets using the <code>train_test_split</code> function.</li>
    <li><b>Build Model:</b> Create and train an AdaBoost classifier using scikit-learn's <code>AdaBoostClassifier</code> with a decision tree as the base estimator.</li>
    <li><b>Make Predictions:</b> Use the trained AdaBoost model to predict labels for the test set.</li>
    <li><b>Evaluate Model:</b> Calculate accuracy and confusion matrix to evaluate the performance of the model.</li>
    <li><b>Plot Results:</b> Visualize the actual data points with colors representing class labels.</li>
</ul>

<!-- Include necessary JavaScript libraries if needed -->

</body>
</html>
