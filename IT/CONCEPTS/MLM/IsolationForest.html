<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Isolation Forest Example</title>
    <!-- Include necessary CSS or styling if needed -->
    <link href="../estilos.css" rel="stylesheet" type="text/css">
</head>
<body class="texto8_1">

<h1>Isolation Forest Example</h1>

<p>This is a simple example of Isolation Forest using Python and scikit-learn.</p>

<h2>Isolation Forest Overview</h2>

<p>Isolation Forest is an anomaly detection algorithm that isolates outliers in a dataset. It builds an ensemble of decision trees, where each tree is grown by recursively partitioning the data. Anomalies are expected to be easier to isolate and require fewer splits to separate from the rest of the data. The algorithm assigns anomaly scores to data points, and points with higher scores are considered more likely to be outliers.</p>

<p>Key concepts of Isolation Forest:</p>

<ul>
    <li><b>Ensemble of Decision Trees:</b> Multiple trees are constructed to identify anomalies in the data.</li>
    <li><b>Isolation:</b> Anomalies are expected to be isolated with shorter paths in the tree structure.</li>
    <li><b>Anomaly Score:</b> A measure of how easily a data point can be isolated; higher scores indicate higher likelihood of being an anomaly.</li>
    <li><b>Forest Structure:</b> The ensemble structure allows Isolation Forest to efficiently detect anomalies even in high-dimensional data.</li>
</ul>

<p>Isolation Forest is particularly useful for detecting anomalies in datasets where anomalies are rare and have different characteristics than normal instances.</p>

<p>Python Source Code:</p>

<pre><code># Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs
from sklearn.ensemble import IsolationForest

# Generate synthetic data with two clusters and outliers
np.random.seed(42)
X, _ = make_blobs(n_samples=300, centers=2, random_state=42)
outliers = np.array([[10, 10]])

# Add outliers to the data
X = np.concatenate([X, outliers])

# Build an Isolation Forest model
iso_forest = IsolationForest(contamination=0.03, random_state=42)
iso_forest.fit(X)

# Predict anomaly scores for the data
anomaly_scores = iso_forest.decision_function(X)

# Plot the results
plt.scatter(X[:, 0], X[:, 1], c='blue', marker='o', edgecolors='black', label='Normal Instances')
plt.scatter(outliers[:, 0], outliers[:, 1], c='red', marker='x', label='Outliers')
plt.title('Isolation Forest Example')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()

# Plot decision boundary based on anomaly scores
xx, yy = np.meshgrid(np.linspace(X[:, 0].min(), X[:, 0].max(), 100),
                     np.linspace(X[:, 1].min(), X[:, 1].max(), 100))
Z = iso_forest.decision_function(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='black', linestyles='dashed')
plt.show()
</code></pre>

<p>Explanation:</p>

<ul>
    <li><b>Import Libraries:</b> Import necessary Python libraries, including NumPy for numerical operations, Matplotlib for plotting, and scikit-learn for dataset generation and Isolation Forest.</li>
    <li><b>Generate Synthetic Data:</b> Create synthetic data with two clusters and add outliers.</li>
    <li><b>Build Model:</b> Create and train an Isolation Forest model using scikit-learn's <code>IsolationForest</code>.</li>
    <li><b>Predict Anomaly Scores:</b> Use the trained Isolation Forest model to predict anomaly scores for each data point.</li>
    <li><b>Plot Results:</b> Visualize the data points, highlight outliers, and plot the decision boundary based on anomaly scores.</li>
</ul>

<!-- Include necessary JavaScript libraries if needed -->

</body>
</html>
