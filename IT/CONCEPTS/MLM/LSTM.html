<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Long Short-Term Memory (LSTM) Example</title>
    <!-- Include necessary CSS or styling if needed -->
    <link href="../estilos.css" rel="stylesheet" type="text/css">
</head>
<body class="texto8_1">

<h1>Long Short-Term Memory (LSTM) Example</h1>

<p>This is a simple example of Long Short-Term Memory (LSTM) using Python and TensorFlow/Keras.</p>

<h2>Long Short-Term Memory (LSTM) Overview</h2>

<p>Long Short-Term Memory (LSTM) networks are a type of recurrent neural network (RNN) designed to address the vanishing gradient problem and capture long-term dependencies in sequential data. LSTMs use memory cells with self-gating mechanisms to selectively store and retrieve information over extended sequences, making them well-suited for tasks such as time series prediction, natural language processing, and more.</p>

<p>Key concepts of Long Short-Term Memory:</p>

<ul>
    <li><b>Memory Cells:</b> Specialized units that can store and update information over long sequences.</li>
    <li><b>Cell State:</b> The internal memory of an LSTM that carries information across time steps.</li>
    <li><b>Input, Forget, Output Gates:</b> Gating mechanisms that control the flow of information into, out of, and within the memory cell.</li>
    <li><b>Long-Term and Short-Term Memory:</b> LSTMs can selectively retain important information for long periods and forget irrelevant information.</li>
</ul>

<p>Python Source Code:</p>

<pre><code># Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.metrics import mean_squared_error

# Generate synthetic time series data
np.random.seed(42)
time = np.arange(0, 100, 1)
sinusoid = np.sin(0.1 * time) + 0.1 * np.random.randn(100)

# Create input sequences and corresponding target values
X, y = [], []
sequence_length = 10

for i in range(len(sinusoid) - sequence_length):
    X.append(sinusoid[i:i+sequence_length])
    y.append(sinusoid[i+sequence_length])

X, y = np.array(X), np.array(y)

# Reshape the input data for LSTM
X = X.reshape(X.shape[0], X.shape[1], 1)

# Build an LSTM model
model = Sequential([
    LSTM(10, activation='relu', input_shape=(sequence_length, 1)),
    Dense(1)
])

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
model.fit(X, y, epochs=50, verbose=0)

# Make predictions on the entire time series
y_pred = model.predict(X)

# Plot the results
plt.plot(time, sinusoid, label='Original Data', marker='o')
plt.plot(time[sequence_length:], y_pred, label='LSTM Predictions', marker='x')
plt.title('Long Short-Term Memory (LSTM) Example')
plt.xlabel('Time')
plt.ylabel('Value')
plt.legend()
plt.show()
</code></pre>

<p>Explanation:</p>

<ul>
    <li><b>Import Libraries:</b> Import necessary Python libraries, including NumPy for numerical operations, Matplotlib for plotting, and TensorFlow/Keras for building and training neural networks.</li>
    <li><b>Generate Synthetic Data:</b> Create synthetic time series data with a sinusoidal pattern and some random noise.</li>
    <li><b>Prepare Input Sequences:</b> Create input sequences and corresponding target values for training the LSTM.</li>
    <li><b>Build Model:</b> Create an LSTM model using TensorFlow/Keras with an LSTM layer and a Dense output layer.</li>
    <li><b>Compile Model:</b> Compile the model specifying the optimizer and loss function for training.</li>
    <li><b>Train Model:</b> Train the LSTM model on the time series data.</li>
    <li><b>Make Predictions:</b> Use the trained LSTM model to make predictions on the entire time series.</li>
    <li><b>Plot Results:</b> Plot the original data and LSTM predictions for visualization.</li>
</ul>

<!-- Include necessary JavaScript libraries if needed -->

</body>
</html>
