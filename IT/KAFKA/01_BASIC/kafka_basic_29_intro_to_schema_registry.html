<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Kafka: Introduction to Schema Registry</title>
    <style>
        body {
            font-family: Arial, Calibri, sans-serif;
            line-height: 1.6;
        }
        h1, h2 {
            color: #333;
        }
        pre {
            background-color: #f4f4f4;
            padding: 10px;
            border-radius: 5px;
        }
        code {
            font-family: Consolas, "Courier New", monospace;
        }
    </style>
</head>
<body>
    <h1>Kafka: Introduction to Schema Registry</h1>
    <p>Schema Registry is a service that provides a central repository for managing and validating schemas used in Kafka topics. It ensures that the data being produced and consumed adheres to a specified schema, facilitating compatibility and data integrity in a distributed system.</p>

    <h2>1. What is Schema Registry?</h2>
    <p>Schema Registry is a component of the Confluent Platform that provides a centralized repository for managing schemas. It supports various schema formats, including Avro, JSON, and Protobuf, and integrates with Kafka producers and consumers to enforce schema validation.</p>

    <h2>2. Why Use Schema Registry?</h2>
    <p>Using Schema Registry offers several benefits:</p>
    <ul>
        <li><strong>Data Compatibility:</strong> Ensures that the data produced and consumed conforms to a specified schema, preventing data format issues.</li>
        <li><strong>Schema Evolution:</strong> Supports schema versioning and evolution, allowing you to update schemas while maintaining compatibility with existing data.</li>
        <li><strong>Data Validation:</strong> Validates data against schemas before it is published to Kafka topics, reducing errors and inconsistencies.</li>
    </ul>

    <h2>3. Key Concepts</h2>
    <p>Here are some key concepts related to Schema Registry:</p>
    <ul>
        <li><strong>Schema:</strong> A definition of the data structure, such as Avro, JSON, or Protobuf schema.</li>
        <li><strong>Subject:</strong> A logical grouping of schemas, typically associated with a Kafka topic.</li>
        <li><strong>Version:</strong> Schema versions are used to track changes and support schema evolution.</li>
    </ul>

    <h2>4. Setting Up Schema Registry</h2>
    <p>To set up Schema Registry, follow these steps:</p>
    <ol>
        <li><strong>Download and Install:</strong> Download the Schema Registry from the Confluent Platform and install it on your system.</li>
        <li><strong>Configuration:</strong> Configure Schema Registry by setting properties in the `schema-registry.properties` file, such as specifying the Kafka bootstrap servers.</li>
        <li><strong>Start the Service:</strong> Start the Schema Registry service using the provided scripts or commands.</li>
    </ol>

    <h3>Example: Schema Registry Configuration</h3>
    <p>Add the following properties to your `schema-registry.properties` file:</p>
    <pre><code>
kafkastore.bootstrap.servers=localhost:9092
kafkastore.topic=_schemas
debug=true
    </code></pre>

    <h2>5. Using Schema Registry with Kafka</h2>
    <p>To use Schema Registry with Kafka, configure your Kafka producers and consumers to use the Schema Registry client libraries. This involves:</p>
    <ul>
        <li><strong>Producer Configuration:</strong> Set up the producer to serialize data using the schema from the Schema Registry.</li>
        <li><strong>Consumer Configuration:</strong> Configure the consumer to deserialize data using the schema from the Schema Registry.</li>
    </ul>

    <h3>Example: Avro Producer Configuration</h3>
    <p>Configure a Kafka producer with Avro serialization:</p>
    <pre><code>
import io.confluent.kafka.serializers.KafkaAvroSerializer;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;

import java.util.Properties;

public class AvroProducerExample {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, KafkaAvroSerializer.class.getName());
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, KafkaAvroSerializer.class.getName());
        props.put("schema.registry.url", "http://localhost:8081");

        KafkaProducer<String, Object> producer = new KafkaProducer<>(props);

        // Create and send a record
        ProducerRecord<String, Object> record = new ProducerRecord<>("my-topic", "key", "value");
        producer.send(record);

        producer.close();
    }
}
    </code></pre>

    <h2>6. Conclusion</h2>
    <p>Schema Registry is an essential tool for managing schemas in Kafka, ensuring data compatibility, and supporting schema evolution. By integrating Schema Registry with your Kafka producers and consumers, you can achieve better data quality and consistency across your distributed systems.</p>
</body>
</html>
