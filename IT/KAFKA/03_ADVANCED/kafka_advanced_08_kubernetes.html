<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Kafka Streams on Kubernetes</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f4f4f4;
        }
        h1, h2 {
            color: #333;
        }
        pre {
            background-color: #272822;
            color: #f8f8f2;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
        }
        code {
            color: #a6e22e;
        }
    </style>
</head>
<body>

    <h1>Kafka Streams on Kubernetes</h1>

    <p>In this guide, we will learn how to deploy a Kafka Streams application on a Kubernetes cluster. We will deploy both Kafka itself and a Kafka Streams application using Kubernetes manifests and Helm charts.</p>

    <h2>Prerequisites</h2>
    <ul>
        <li>A running Kubernetes cluster (e.g., using <b>Minikube</b>, <b>Kind</b>, or a cloud provider like <b>EKS</b> or <b>GKE</b>).</li>
        <li>Kubectl installed and configured to connect to the cluster.</li>
        <li>Helm installed for easier deployment of Kafka.</li>
        <li>A basic understanding of Kafka and Kubernetes concepts.</li>
    </ul>

    <h2>Step 1: Deploy Kafka on Kubernetes</h2>
    <p>First, we need to deploy Kafka on our Kubernetes cluster. The easiest way to deploy Kafka is by using Helm charts.</p>

    <h3>Using Helm to Install Kafka</h3>
    <p>We will use the Bitnami Kafka Helm chart to deploy Kafka:</p>

    <pre><code># Add Bitnami Helm repository
helm repo add bitnami https://charts.bitnami.com/bitnami

# Update Helm repositories
helm repo update

# Install Kafka
helm install kafka bitnami/kafka --set replicaCount=1 --set zookeeper.replicaCount=1</code></pre>

    <p>This command installs a single-node Kafka and Zookeeper setup on the Kubernetes cluster.</p>

    <h2>Step 2: Deploy the Kafka Streams Application</h2>
    <p>We will now deploy the Kafka Streams application (similar to the ETL example) on Kubernetes using a Docker container and Kubernetes manifests.</p>

    <h3>Dockerizing the Kafka Streams Application</h3>
    <p>Create a <code>Dockerfile</code> to package the Kafka Streams application:</p>

    <pre><code># Dockerfile for Kafka Streams Application

FROM openjdk:17-jdk-slim
COPY target/kafka-streams-etl.jar /app/kafka-streams-etl.jar
WORKDIR /app
CMD ["java", "-jar", "kafka-streams-etl.jar"]</code></pre>

    <p>Build the Docker image:</p>

    <pre><code># Build the Docker image
docker build -t yourusername/kafka-streams-etl:latest .</code></pre>

    <p>Push the image to a container registry (e.g., Docker Hub or another registry):</p>

    <pre><code># Push the image to Docker Hub
docker push yourusername/kafka-streams-etl:latest</code></pre>

    <h3>Creating Kubernetes Deployment and Service for the Kafka Streams Application</h3>
    <p>Now, create a Kubernetes deployment and service YAML file for the Kafka Streams application:</p>

    <pre><code>---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-streams-etl
  labels:
    app: kafka-streams-etl
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kafka-streams-etl
  template:
    metadata:
      labels:
        app: kafka-streams-etl
    spec:
      containers:
      - name: kafka-streams-etl
        image: yourusername/kafka-streams-etl:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
        env:
        - name: KAFKA_BROKER
          value: "kafka:9092"
        - name: INPUT_TOPIC
          value: "input-topic"
        - name: OUTPUT_TOPIC
          value: "output-topic"
---
apiVersion: v1
kind: Service
metadata:
  name: kafka-streams-etl
spec:
  selector:
    app: kafka-streams-etl
  ports:
  - protocol: TCP
    port: 8080
    targetPort: 8080
</code></pre>

    <h2>Step 3: Deploying the Kafka Streams Application</h2>
    <p>Apply the Kubernetes manifests to deploy the Kafka Streams application:</p>

    <pre><code># Apply the Kafka Streams application deployment
kubectl apply -f kafka-streams-deployment.yaml</code></pre>

    <p>This will create a pod that runs your Kafka Streams application and a service to expose it.</p>

    <h2>Step 4: Verifying the Deployment</h2>
    <p>Check if the Kafka Streams application is running by listing the pods:</p>

    <pre><code># List running pods
kubectl get pods</code></pre>

    <p>You should see a pod named <code>kafka-streams-etl</code> in the list. You can check the logs of the Kafka Streams application using:</p>

    <pre><code># View logs of Kafka Streams application
kubectl logs kafka-streams-etl</code></pre>

    <h2>Step 5: Producing and Consuming Messages</h2>
    <p>You can produce messages to the Kafka topic using Kafka console producer:</p>

    <pre><code># Produce messages to Kafka topic
kubectl exec -it $(kubectl get pods | grep kafka | awk '{print $1}') -- kafka-console-producer.sh --broker-list kafka:9092 --topic input-topic
&gt; message1
&gt; message2</code></pre>

    <p>Then, consume messages from the output topic:</p>

    <pre><code># Consume messages from Kafka output topic
kubectl exec -it $(kubectl get pods | grep kafka | awk '{print $1}') -- kafka-console-consumer.sh --bootstrap-server kafka:9092 --topic output-topic --from-beginning</code></pre>

    <h2>Conclusion</h2>
    <p>In this guide, we learned how to deploy a Kafka Streams application on a Kubernetes cluster. We used Helm to install Kafka and Kubernetes manifests to deploy our Kafka Streams ETL pipeline. This setup allows for scalable, resilient, real-time data streaming and transformation in a cloud-native environment.</p>

</body>
</html>
