<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multi-Tenant Kafka Streams</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f4f4f4;
        }
        h1, h2 {
            color: #333;
        }
        pre {
            background-color: #272822;
            color: #f8f8f2;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
        }
        code {
            color: #a6e22e;
        }
    </style>
</head>
<body>

    <h1>Multi-Tenant Kafka Streams Application</h1>

    <p>In this guide, we'll explore how to implement a multi-tenant Kafka Streams application. Multi-tenancy in Kafka refers to the ability to serve multiple clients (tenants) from a single Kafka cluster or application, while keeping data and processing isolated per tenant.</p>

    <h2>Concept of Multi-Tenancy in Kafka</h2>
    <p>In a multi-tenant Kafka environment, each tenant could be given its own:</p>
    <ul>
        <li><b>Kafka topics:</b> Separate topics per tenant for data segregation.</li>
        <li><b>Stream processing logic:</b> Each tenant might need different processing logic.</li>
        <li><b>Consumer groups:</b> To consume messages independently.</li>
        <li><b>Security configurations:</b> Tenant-specific authentication and authorization.</li>
    </ul>

    <h2>Approaches to Multi-Tenancy in Kafka</h2>
    <h3>1. Isolated Topics Per Tenant</h3>
    <p>Each tenant has its own input and output topics. This ensures data isolation and tenant-specific processing. Tenant-specific topics could follow a naming convention like:</p>

    <pre><code>input-topic-tenant1, input-topic-tenant2, output-topic-tenant1, output-topic-tenant2</code></pre>

    <h3>2. Shared Topics with Tenant Identifiers</h3>
    <p>All tenants share a single set of topics, and each message includes a tenant identifier (e.g., in the message key or headers). Kafka Streams can route and process messages based on this tenant identifier.</p>

    <h3>3. Separate Consumer Groups</h3>
    <p>Each tenant has its own consumer group. The Kafka Streams application uses different consumer group IDs for each tenant, allowing independent consumption and processing.</p>

    <h2>Step-by-Step Example: Isolated Topics Per Tenant</h2>
    <p>We will now implement a multi-tenant Kafka Streams application where each tenant has its own Kafka topics for input and output.</p>

    <h3>Step 1: Kafka Streams Application Logic</h3>
    <p>The Kafka Streams application will handle multiple tenants by dynamically creating Kafka Streams topology based on the tenant's topics. Each tenant will have its own input and output topic.</p>

    <pre><code>// MultiTenantKafkaStreamsApp.java
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.kstream.KStream;

import java.util.HashMap;
import java.util.Map;
import java.util.Properties;

public class MultiTenantKafkaStreamsApp {

    private static final Map&lt;String, KafkaStreams&gt; tenantStreams = new HashMap&lt;&gt;();

    public static void main(String[] args) {
        // List of tenants
        String[] tenants = {"tenant1", "tenant2"};

        for (String tenant : tenants) {
            KafkaStreams streams = createKafkaStreams(tenant);
            tenantStreams.put(tenant, streams);
            streams.start();
        }

        Runtime.getRuntime().addShutdownHook(new Thread(() -> {
            tenantStreams.values().forEach(KafkaStreams::close);
        }));
    }

    private static KafkaStreams createKafkaStreams(String tenant) {
        // Configure the properties for the Kafka Streams instance for each tenant
        Properties props = new Properties();
        props.put(StreamsConfig.APPLICATION_ID_CONFIG, "kafka-streams-app-" + tenant);
        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
        props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());

        // Create a StreamsBuilder instance
        StreamsBuilder builder = new StreamsBuilder();

        // Define tenant-specific input and output topics
        String inputTopic = "input-topic-" + tenant;
        String outputTopic = "output-topic-" + tenant;

        // Define the stream processing logic
        KStream&lt;String, String&gt; inputStream = builder.stream(inputTopic);
        KStream&lt;String, String&gt; outputStream = inputStream.mapValues(value -> "Processed: " + value);

        // Send processed data to tenant-specific output topic
        outputStream.to(outputTopic);

        // Build and return the KafkaStreams instance
        return new KafkaStreams(builder.build(), props);
    }
}
</code></pre>

    <h3>Explanation</h3>
    <p>This code defines a Kafka Streams application that creates a separate stream topology for each tenant. Each tenant has its own input and output topics, and the application processes data for each tenant independently.</p>
    <ul>
        <li><code>createKafkaStreams()</code> creates a Kafka Streams instance for a specific tenant by configuring tenant-specific topics and properties.</li>
        <li>The application uses a <code>HashMap</code> to store and manage the Kafka Streams instances for each tenant.</li>
    </ul>

    <h3>Step 2: Kafka Topic Configuration for Tenants</h3>
    <p>To ensure each tenant has its own topics, create Kafka topics for each tenant. You can create the topics manually or programmatically using Kafka Admin API.</p>

    <pre><code># Create topics for each tenant
kafka-topics.sh --create --topic input-topic-tenant1 --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
kafka-topics.sh --create --topic output-topic-tenant1 --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1

kafka-topics.sh --create --topic input-topic-tenant2 --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
kafka-topics.sh --create --topic output-topic-tenant2 --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
</code></pre>

    <h3>Step 3: Deploy the Kafka Streams Application</h3>
    <p>We can now deploy the Kafka Streams application. Ensure that the application is packaged and run as a JAR, or it can be containerized with Docker for Kubernetes deployment.</p>

    <h3>Step 4: Produce and Consume Messages Per Tenant</h3>
    <p>To test the multi-tenant setup, we can produce and consume messages for each tenant using Kafka console producer and consumer commands.</p>

    <pre><code># Produce messages for tenant1
kafka-console-producer.sh --broker-list localhost:9092 --topic input-topic-tenant1
&gt; message1 for tenant1

# Consume messages for tenant1
kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic output-topic-tenant1 --from-beginning

# Produce messages for tenant2
kafka-console-producer.sh --broker-list localhost:9092 --topic input-topic-tenant2
&gt; message1 for tenant2

# Consume messages for tenant2
kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic output-topic-tenant2 --from-beginning
</code></pre>

    <h3>Step 5: Scaling Kafka Streams for Multiple Tenants</h3>
    <p>To scale the application, you can dynamically add tenants by introducing new tenant IDs and creating new input/output topics as needed. Kafka Streams can be scaled horizontally by deploying multiple instances of the application on Kubernetes or a cloud provider like AWS or GCP.</p>

    <h2>Conclusion</h2>
    <p>In this guide, we explored how to build a multi-tenant Kafka Streams application by isolating tenants with separate topics and consumer groups. We demonstrated how to deploy a multi-tenant Kafka application, create tenant-specific topics, and handle tenant-based data processing independently. This setup is flexible and can scale as the number of tenants increases, making Kafka a powerful choice for multi-tenant stream processing architectures.</p>

</body>
</html>
