<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Kafka Advanced: Exactly-Once Semantics</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
        }
        header {
            background: #333;
            color: #fff;
            padding: 1rem 0;
            text-align: center;
        }
        .container {
            width: 80%;
            margin: auto;
            overflow: hidden;
            padding: 20px;
        }
        h1, h2, h3 {
            color: #333;
        }
        pre {
            background: #eee;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 5px;
            overflow-x: auto;
        }
        code {
            background: #f9f9f9;
            padding: 5px;
            border-radius: 3px;
        }
        .section {
            margin-bottom: 20px;
        }
        .example-code {
            background: #282c34;
            color: #61dafb;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
        }
    </style>
</head>
<body>
    <header>
        <h1>Kafka Advanced: Exactly-Once Semantics</h1>
    </header>

    <div class="container">
        <section class="section">
            <h2>Introduction to Exactly-Once Semantics</h2>
            <p>
                Exactly-Once Semantics (EOS) in Apache Kafka ensures that records are neither lost nor processed more than once. This guarantees data integrity and accuracy in applications that require precise processing, such as financial transactions or critical data processing systems.
            </p>
            <p>
                EOS involves handling several challenges such as ensuring idempotency, managing offsets, and coordinating between producers and consumers to prevent duplicate or lost messages.
            </p>
        </section>

        <section class="section">
            <h2>Why Exactly-Once Semantics Matters</h2>
            <p>
                Traditional message processing systems often face issues such as:
            </p>
            <ul>
                <li><strong>Duplicate Messages:</strong> When messages are reprocessed due to errors or retries.</li>
                <li><strong>Message Loss:</strong> When messages are not persisted or fail to be delivered.</li>
                <li><strong>Out-of-Order Processing:</strong> When the order of messages is not guaranteed.</li>
            </ul>
            <p>
                Exactly-Once Semantics address these issues by ensuring that each message is processed exactly once, thereby maintaining data consistency and reliability.
            </p>
        </section>

        <section class="section">
            <h2>How Exactly-Once Semantics Works in Kafka</h2>
            <p>
                Kafka achieves Exactly-Once Semantics through the combination of producer idempotence, transactional messaging, and consumer offset management.
            </p>

            <h3>Producer Idempotence</h3>
            <p>
                Idempotence ensures that a message is not produced more than once with the same producer ID. This is achieved by assigning a unique ID to each producer, which Kafka uses to detect and discard duplicate messages.
            </p>
            <pre><code>
# Producer Configuration for Idempotence
properties.put("enable.idempotence", "true");
            </code></pre>

            <h3>Transactional Messaging</h3>
            <p>
                Kafka transactions allow for atomic writes to multiple partitions, ensuring that either all messages are committed or none are. This is useful for operations that span multiple partitions or topics.
            </p>
            <pre><code>
# Producer Configuration for Transactions
properties.put("acks", "all");
properties.put("transactional.id", "your-transactional-id");
            </code></pre>

            <h3>Consumer Offset Management</h3>
            <p>
                Kafka manages offsets to keep track of which messages have been processed. By committing offsets only after successful processing, Kafka ensures that messages are not reprocessed.
            </p>
            <pre><code>
# Consumer Configuration for Offsets
properties.put("enable.auto.commit", "false");
            </code></pre>
        </section>

        <section class="section">
            <h2>Implementing Exactly-Once Semantics</h2>
            <p>
                To implement EOS, follow these steps:
            </p>
            <ol>
                <li><strong>Enable Idempotence:</strong> Configure the Kafka producer for idempotence.</li>
                <li><strong>Use Transactions:</strong> Start and commit transactions for producing messages.</li>
                <li><strong>Manage Offsets:</strong> Disable auto-commit for consumers and manually commit offsets after processing.</li>
            </ol>

            <h3>Example: Idempotent Producer and Transactional Messaging</h3>
            <pre><code>
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.Producer;
import java.util.Properties;

public class ExactlyOnceProducer {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringSerializer");
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringSerializer");
        props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, "true");
        props.put(ProducerConfig.ACKS_CONFIG, "all");
        props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, "my-transactional-id");

        Producer<String, String> producer = new KafkaProducer<>(props);
        producer.initTransactions();

        try {
            producer.beginTransaction();
            producer.send(new ProducerRecord<>("my-topic", "key", "value"));
            producer.commitTransaction();
        } catch (Exception e) {
            producer.abortTransaction();
        } finally {
            producer.close();
        }
    }
}
            </code></pre>

            <h3>Example: Consumer with Manual Offset Management</h3>
            <pre><code>
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.Consumer;
import org.apache.kafka.common.serialization.StringDeserializer;
import java.util.Collections;
import java.util.Properties;

public class ExactlyOnceConsumer {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(ConsumerConfig.GROUP_ID_CONFIG, "my-group");
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "false");

        Consumer<String, String> consumer = new KafkaConsumer<>(props);
        consumer.subscribe(Collections.singletonList("my-topic"));

        try {
            while (true) {
                for (ConsumerRecord<String, String> record : consumer.poll(100)) {
                    // Process record
                    System.out.printf("Consumed record with key %s and value %s%n", record.key(), record.value());
                }
                consumer.commitSync();
            }
        } finally {
            consumer.close();
        }
    }
}
            </code></pre>
        </section>

        <section class="section">
            <h2>Conclusion</h2>
            <p>
                Exactly-Once Semantics in Kafka provides a robust solution for ensuring data consistency and integrity in distributed systems. By leveraging producer idempotence, transactional messaging, and careful offset management, Kafka applications can achieve exactly-once processing guarantees.
            </p>
        </section>
    </div>
</body>
</html>
