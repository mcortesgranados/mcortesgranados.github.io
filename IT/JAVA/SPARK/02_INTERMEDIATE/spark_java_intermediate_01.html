<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Spark Cluster Mode Example: Kubernetes</title>
    <style>
        body {
            font-family: Arial, Calibri, sans-serif;
            line-height: 1.6;
        }
        h1, h2 {
            color: #333;
        }
        pre {
            background-color: #f4f4f4;
            padding: 10px;
            border-radius: 5px;
        }
        code {
            font-family: Consolas, "Courier New", monospace;
        }
    </style>
</head>
<body>
    <h1>Running a Spark Application on Kubernetes</h1>
    <p>This example demonstrates how to submit a Spark job to a Kubernetes cluster using a Java application.</p>

    <h2>Prerequisites</h2>
    <ul>
        <li>Apache Spark 3.x</li>
        <li>Kubernetes cluster (e.g., Minikube, GKE, AKS)</li>
        <li>Docker installed and configured</li>
    </ul>

    <h2>Step 1: Create a Simple Java Spark Application</h2>
    <pre><code>
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.api.java.JavaRDD;

public class SparkKubernetesExample {
    public static void main(String[] args) {
        // Step 1: Create a SparkConf object and set the application name
        SparkConf conf = new SparkConf().setAppName("Spark Kubernetes Example");
        
        // Step 2: Create a JavaSparkContext object
        JavaSparkContext sc = new JavaSparkContext(conf);
        
        // Step 3: Load a text file from HDFS or local file system
        JavaRDD&lt;String&gt; textFile = sc.textFile("hdfs://path/to/textfile.txt");
        
        // Step 4: Perform a simple word count operation
        JavaRDD&lt;String&gt; words = textFile.flatMap(line -> Arrays.asList(line.split(" ")).iterator());
        long wordCount = words.count();
        
        // Step 5: Print the result
        System.out.println("Total number of words: " + wordCount);
        
        // Step 6: Stop the Spark context
        sc.stop();
    }
}
    </code></pre>

    <h2>Step 2: Build and Package the Application</h2>
    <p>Use Maven or Gradle to build and package the application into a JAR file.</p>

    <h2>Step 3: Create a Docker Image</h2>
    <p>To run this application on Kubernetes, you'll need to create a Docker image that contains the Spark application.</p>
    <pre><code>
# Dockerfile
FROM openjdk:8-jdk-alpine
ADD target/SparkKubernetesExample.jar /app/SparkKubernetesExample.jar
ENTRYPOINT ["java", "-cp", "/app/SparkKubernetesExample.jar", "SparkKubernetesExample"]
    </code></pre>

    <p>Build the Docker image:</p>
    <pre><code>
docker build -t your_dockerhub_username/spark-kubernetes-example .
    </code></pre>

    <h2>Step 4: Deploy on Kubernetes</h2>
    <p>Deploy the Spark application on Kubernetes using the following command:</p>
    <pre><code>
kubectl run spark-kubernetes-example --image=your_dockerhub_username/spark-kubernetes-example --restart=Never
    </code></pre>

    <h2>Step 5: Monitor the Application</h2>
    <p>Monitor the Spark application using Kubernetes Dashboard or command-line tools:</p>
    <pre><code>
kubectl logs -f spark-kubernetes-example
    </code></pre>

    <h2>Conclusion</h2>
    <p>This example shows how to submit a simple Spark application to a Kubernetes cluster. Adjust the example as needed for more complex applications and configurations.</p>
</body>
</html>
