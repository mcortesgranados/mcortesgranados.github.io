<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Basic Spark SQL Operations</title>
    <style>
        body {
            font-family: Arial, Calibri, sans-serif;
            line-height: 1.6;
        }
        h1, h2 {
            color: #333;
        }
        pre {
            background-color: #f4f4f4;
            padding: 10px;
            border-radius: 5px;
        }
        code {
            font-family: Consolas, "Courier New", monospace;
        }
    </style>
</head>
<body>
    <h1>Basic Spark SQL Operations</h1>
    <p>This guide introduces basic Spark SQL operations with examples in Java.</p>

    <h2>What is Spark SQL?</h2>
    <p>Spark SQL is a module in Apache Spark that allows for querying structured data using SQL syntax. It enables users to interact with Spark through SQL queries, making it easier to work with data from different sources.</p>

    <h2>Creating DataFrames from SQL Queries</h2>
    <p>In Spark SQL, you can run SQL queries on DataFrames to extract, filter, and aggregate data. Below is an example of how to create a DataFrame and run basic SQL operations on it.</p>

    <h3>Example: Running SQL Queries on a DataFrame</h3>
    <pre><code>
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;

public class SparkSQLExample {
    public static void main(String[] args) {
        // Step 1: Create a SparkSession
        SparkSession spark = SparkSession.builder()
                .appName("Basic Spark SQL Operations")
                .master("local[*]")
                .getOrCreate();

        // Step 2: Load data into a DataFrame (this example assumes a JSON file)
        Dataset&lt;Row&gt; df = spark.read().json("path/to/your/file.json");

        // Step 3: Register the DataFrame as a temporary SQL view
        df.createOrReplaceTempView("people");

        // Step 4: Run a SQL query
        Dataset&lt;Row&gt; sqlDF = spark.sql("SELECT name, age FROM people WHERE age > 20");

        // Step 5: Show the results
        sqlDF.show();

        // Step 6: Stop the Spark session
        spark.stop();
    }
}
    </code></pre>

    <h2>Basic SQL Operations in Spark</h2>
    <p>Here are some common SQL operations that can be performed in Spark:</p>

    <ul>
        <li><strong>SELECT:</strong> Extract specific columns from a DataFrame.</li>
        <li><strong>WHERE:</strong> Filter data based on specific conditions.</li>
        <li><strong>GROUP BY:</strong> Group data by a specific column and perform aggregations.</li>
        <li><strong>ORDER BY:</strong> Sort data based on one or more columns.</li>
        <li><strong>JOIN:</strong> Combine data from two or more DataFrames based on a common key.</li>
    </ul>

    <h3>Example: Using GROUP BY and Aggregations</h3>
    <pre><code>
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;

public class GroupByExample {
    public static void main(String[] args) {
        // Step 1: Create a SparkSession
        SparkSession spark = SparkSession.builder()
                .appName("Group By and Aggregations")
                .master("local[*]")
                .getOrCreate();

        // Step 2: Load data into a DataFrame (this example assumes a JSON file)
        Dataset&lt;Row&gt; df = spark.read().json("path/to/your/file.json");

        // Step 3: Register the DataFrame as a temporary SQL view
        df.createOrReplaceTempView("people");

        // Step 4: Run a SQL query with GROUP BY and aggregation
        Dataset&lt;Row&gt; groupedDF = spark.sql("SELECT age, COUNT(*) as count FROM people GROUP BY age");

        // Step 5: Show the results
        groupedDF.show();

        // Step 6: Stop the Spark session
        spark.stop();
    }
}
    </code></pre>

    <h2>Performing Joins with Spark SQL</h2>
    <p>Joins allow you to combine data from multiple DataFrames or SQL tables based on a common key. Here's an example of performing a join operation in Spark SQL.</p>

    <h3>Example: Joining Two DataFrames</h3>
    <pre><code>
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;

public class JoinExample {
    public static void main(String[] args) {
        // Step 1: Create a SparkSession
        SparkSession spark = SparkSession.builder()
                .appName("Join Example")
                .master("local[*]")
                .getOrCreate();

        // Step 2: Load two DataFrames
        Dataset&lt;Row&gt; df1 = spark.read().json("path/to/people.json");
        Dataset&lt;Row&gt; df2 = spark.read().json("path/to/employment.json");

        // Step 3: Create temporary views for both DataFrames
        df1.createOrReplaceTempView("people");
        df2.createOrReplaceTempView("employment");

        // Step 4: Run a SQL query to join both DataFrames
        Dataset&lt;Row&gt; joinDF = spark.sql(
            "SELECT p.name, p.age, e.job_title FROM people p JOIN employment e ON p.id = e.person_id");

        // Step 5: Show the results
        joinDF.show();

        // Step 6: Stop the Spark session
        spark.stop();
    }
}
    </code></pre>

    <h2>Understanding the Examples</h2>
    <p>In each of the examples, the following steps are performed:</p>
    <ol>
        <li><strong>Create a SparkSession:</strong> This is required to work with Spark DataFrames and SQL queries.</li>
        <li><strong>Load data into DataFrames:</strong> The data can be loaded from various sources, such as JSON or CSV files.</li>
        <li><strong>Create a temporary SQL view:</strong> The DataFrame is registered as a temporary view to run SQL queries against it.</li>
        <li><strong>Run SQL queries:</strong> Standard SQL syntax is used to query and manipulate the data.</li>
        <li><strong>Show the results:</strong> The <code>show()</code> method displays the output of the SQL query.</li>
    </ol>

    <h2>Conclusion</h2>
    <p>Spark SQL provides a powerful and flexible way to work with structured data using SQL queries. With operations such as <code>SELECT</code>, <code>WHERE</code>, <code>GROUP BY</code>, and <code>JOIN</code>, you can perform complex data manipulations and analyses directly on your DataFrames.</p>
</body>
</html>
