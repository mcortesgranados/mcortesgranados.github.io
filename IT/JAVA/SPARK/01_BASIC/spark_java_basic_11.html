<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Basic Operations on RDDs</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
        }
        h1, h2 {
            color: #333;
        }
        code {
            background: #f4f4f4;
            padding: 2px 4px;
            border-radius: 4px;
            font-size: 0.9em;
        }
        pre {
            background: #f4f4f4;
            padding: 10px;
            border-radius: 4px;
            overflow-x: auto;
        }
    </style>
</head>
<body>
    <h1>Basic Operations on RDDs</h1>

    <p>In Apache Spark, RDDs (Resilient Distributed Datasets) provide a powerful abstraction for distributed data processing. This document explains some basic operations that can be performed on RDDs and provides a Java code example to illustrate these operations.</p>

    <h2>Basic RDD Operations</h2>
    <p>RDD operations can be broadly categorized into transformations and actions. Here are some fundamental operations:</p>

    <h3>1. <code>map()</code></h3>
    <p>The <code>map()</code> transformation applies a function to each element of the RDD and returns a new RDD with the results.</p>

    <h3>2. <code>filter()</code></h3>
    <p>The <code>filter()</code> transformation returns a new RDD containing only the elements that satisfy a given predicate.</p>

    <h3>3. <code>flatMap()</code></h3>
    <p>The <code>flatMap()</code> transformation applies a function to each element of the RDD and returns a new RDD that can have a different number of elements than the original RDD. It is useful for operations like tokenizing text.</p>

    <h3>4. <code>reduce()</code></h3>
    <p>The <code>reduce()</code> action aggregates the elements of the RDD using a specified function. It is often used to compute a summary statistic or combine results.</p>

    <h3>5. <code>collect()</code></h3>
    <p>The <code>collect()</code> action retrieves all the elements of the RDD and returns them as a list to the driver program.</p>

    <h2>Example Code in Java</h2>
    <p>The following Java code demonstrates some basic operations on RDDs:</p>

    <pre><code class="language-java">
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;

public class BasicOperationsExample {
    public static void main(String[] args) {
        // Create a SparkConf object and set the application name and master
        SparkConf conf = new SparkConf().setAppName("Basic Operations Example").setMaster("local");
        
        // Create a JavaSparkContext with the configuration
        JavaSparkContext sc = new JavaSparkContext(conf);

        // Create an RDD by parallelizing a collection
        JavaRDD<Integer> numbers = sc.parallelize(java.util.Arrays.asList(1, 2, 3, 4, 5));

        // map: Square each number
        JavaRDD<Integer> squaredNumbers = numbers.map(number -> number * number);

        // filter: Keep only even numbers
        JavaRDD<Integer> evenNumbers = squaredNumbers.filter(number -> number % 2 == 0);

        // flatMap: Convert each number to a list of strings
        JavaRDD<String> numberStrings = evenNumbers.flatMap(number -> java.util.Arrays.asList("Number: " + number).iterator());

        // reduce: Sum all numbers
        int sum = numbers.reduce((a, b) -> a + b);

        // collect: Retrieve and print the results
        System.out.println("Squared Even Numbers:");
        numberStrings.collect().forEach(System.out::println);

        System.out.println("Sum of Numbers: " + sum);

        // Stop the SparkContext
        sc.close();
    }
}
    </code></pre>

    <p>In this example:</p>
    <ul>
        <li><strong>map:</strong> We use <code>map()</code> to square each number in the RDD.</li>
        <li><strong>filter:</strong> We use <code>filter()</code> to keep only even numbers from the squared results.</li>
        <li><strong>flatMap:</strong> We use <code>flatMap()</code> to convert each even number into a string.</li>
        <li><strong>reduce:</strong> We use <code>reduce()</code> to compute the sum of all numbers.</li>
        <li><strong>collect:</strong> We use <code>collect()</code> to retrieve and print the transformed data.</li>
    </ul>

    <p>These basic operations are essential for manipulating and analyzing data in Spark. They provide a foundation for building more complex data processing pipelines.</p>

</body>
</html>
