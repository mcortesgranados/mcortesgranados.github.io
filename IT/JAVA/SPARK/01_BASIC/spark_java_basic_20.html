<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Spark DataFrame Transformations in Java</title>
    <style>
        body {
            font-family: Arial, Calibri, sans-serif;
            line-height: 1.6;
        }
        h1, h2 {
            color: #333;
        }
        pre {
            background-color: #f4f4f4;
            padding: 10px;
            border-radius: 5px;
        }
        code {
            font-family: Consolas, "Courier New", monospace;
        }
    </style>
</head>
<body>
    <h1>Spark DataFrame Transformations in Java</h1>
    <p>This example demonstrates various Spark DataFrame transformations using Java.</p>

    <h2>Java Code Example</h2>
    <pre><code>
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.functions;

public class DataFrameTransformationsExample {
    public static void main(String[] args) {
        // Create SparkSession
        SparkSession spark = SparkSession.builder()
            .appName("DataFrame Transformations Example")
            .master("local[*]")
            .getOrCreate();

        // Create a DataFrame from a JSON file
        Dataset&lt;Row&gt; df = spark.read().json("data/sample.json");

        // Show the initial DataFrame
        df.show();

        // Select specific columns
        Dataset&lt;Row&gt; selectedDF = df.select("name", "age");
        selectedDF.show();

        // Filter rows based on a condition
        Dataset&lt;Row&gt; filteredDF = df.filter(df.col("age").gt(21));
        filteredDF.show();

        // Add a new column with calculated values
        Dataset&lt;Row&gt; withNewColumnDF = df.withColumn("agePlusOne", df.col("age").plus(1));
        withNewColumnDF.show();

        // Drop a column
        Dataset&lt;Row&gt; droppedColumnDF = df.drop("address");
        droppedColumnDF.show();

        // Group by a column and perform aggregation
        Dataset&lt;Row&gt; groupedDF = df.groupBy("city").agg(functions.avg("age").as("average_age"));
        groupedDF.show();

        // Stop SparkSession
        spark.stop();
    }
}
    </code></pre>

    <h2>Understanding the Example</h2>
    <p>In this example, we demonstrate the following DataFrame transformations:</p>
    <ul>
        <li><strong>Select Columns:</strong> We use the <code>select()</code> method to select specific columns from the DataFrame.</li>
        <li><strong>Filter Rows:</strong> The <code>filter()</code> method is used to filter rows based on a condition.</li>
        <li><strong>Add Column:</strong> The <code>withColumn()</code> method is used to add a new column with calculated values.</li>
        <li><strong>Drop Column:</strong> The <code>drop()</code> method removes a column from the DataFrame.</li>
        <li><strong>Group By and Aggregate:</strong> The <code>groupBy()</code> method groups rows based on a column and <code>agg()</code> performs aggregate operations.</li>
    </ul>

    <h2>Conclusion</h2>
    <p>Spark DataFrame transformations provide a powerful and flexible way to manipulate and analyze data. Understanding and leveraging these transformations allows for efficient data processing and querying in Spark applications.</p>
</body>
</html>
