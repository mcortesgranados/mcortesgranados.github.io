<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Structured Streaming vs DStreams Comparison</title>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        pre {
            background-color: #f4f4f4;
            border: 1px solid #ddd;
            padding: 10px;
            overflow-x: auto;
        }
        code {
            font-family: 'Courier New', monospace;
        }
    </style>
</head>
<body>
    <h1>Structured Streaming vs DStreams Comparison</h1>

    <p>
        Spark provides two APIs for stream processing: DStreams (Discretized Streams) and Structured Streaming. Each has its own features, benefits, and use cases. This document compares the two to help understand their differences and use cases.
    </p>

    <h2>DStreams (Discretized Streams)</h2>
    <ul>
        <li><strong>Introduction:</strong> DStreams are the original API in Spark for stream processing. They represent a continuous stream of data as a sequence of RDDs (Resilient Distributed Datasets).</li>
        <li><strong>Batch Interval:</strong> Data is processed in micro-batches with a fixed interval, meaning that each batch is processed as an RDD.</li>
        <li><strong>API Complexity:</strong> DStreams API is lower-level and may require more effort to implement complex stream processing logic.</li>
        <li><strong>Fault Tolerance:</strong> Provides fault tolerance by storing intermediate data in a reliable storage system.</li>
        <li><strong>State Management:</strong> Limited support for stateful operations compared to Structured Streaming.</li>
    </ul>

    <h2>Structured Streaming</h2>
    <ul>
        <li><strong>Introduction:</strong> Structured Streaming is a higher-level API introduced in Spark 2.x that provides a more powerful and flexible way to process streaming data.</li>
        <li><strong>Continuous Processing:</strong> Uses a continuous processing model where data is processed as soon as it arrives, with support for event-time processing and advanced analytics.</li>
        <li><strong>API Simplicity:</strong> Offers a higher-level API with more expressive capabilities, making it easier to build and manage complex stream processing pipelines.</li>
        <li><strong>Fault Tolerance:</strong> Provides improved fault tolerance through checkpointing and write-ahead logs.</li>
        <li><strong>State Management:</strong> Supports complex stateful operations, such as aggregations and joins with stateful processing.</li>
    </ul>

    <h2>Comparison Table</h2>
    <table border="1" cellpadding="10">
        <thead>
            <tr>
                <th>Feature</th>
                <th>DStreams</th>
                <th>Structured Streaming</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>API Level</td>
                <td>Lower-level</td>
                <td>Higher-level</td>
            </tr>
            <tr>
                <td>Processing Model</td>
                <td>Micro-batch</td>
                <td>Continuous or Micro-batch</td>
            </tr>
            <tr>
                <td>Fault Tolerance</td>
                <td>Intermediate data stored in reliable storage</td>
                <td>Checkpointing and write-ahead logs</td>
            </tr>
            <tr>
                <td>State Management</td>
                <td>Limited</td>
                <td>Advanced</td>
            </tr>
            <tr>
                <td>Ease of Use</td>
                <td>More complex</td>
                <td>More expressive and easier to use</td>
            </tr>
        </tbody>
    </table>

    <h2>Example Source Code</h2>
    <p>
        Below are examples demonstrating both DStreams and Structured Streaming using Java.
    </p>

    <h3>DStreams Example</h3>
    <pre><code class="language-java">
import org.apache.spark.SparkConf;
import org.apache.spark.streaming.Durations;
import org.apache.spark.streaming.api.java.JavaDStream;
import org.apache.spark.streaming.api.java.JavaStreamingContext;

public class DStreamsExample {
    public static void main(String[] args) throws InterruptedException {
        // Create a SparkConf
        SparkConf conf = new SparkConf().setAppName("DStreams Example").setMaster("local[*]");
        // Create a JavaStreamingContext with a batch interval of 10 seconds
        JavaStreamingContext jssc = new JavaStreamingContext(conf, Durations.seconds(10));

        // Create a DStream from a TCP source
        JavaDStream<String> lines = jssc.socketTextStream("localhost", 9999);

        // Perform a simple transformation and action
        JavaDStream<Long> lineLengths = lines.map(String::length);
        lineLengths.print();

        // Start the computation
        jssc.start();
        jssc.awaitTermination();
    }
}
    </code></pre>

    <h3>Structured Streaming Example</h3>
    <pre><code class="language-java">
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.types.DataTypes;
import org.apache.spark.sql.types.StructType;

public class StructuredStreamingExample {
    public static void main(String[] args) {
        // Create a SparkSession
        SparkSession spark = SparkSession.builder()
            .appName("Structured Streaming Example")
            .master("local[*]")
            .getOrCreate();

        // Define schema for input data
        StructType schema = new StructType()
            .add("value", DataTypes.StringType);

        // Create a DataFrame from a socket source
        Dataset<Row> df = spark.readStream()
            .schema(schema)
            .json("path/to/input/directory");

        // Perform a simple transformation and action
        Dataset<Row> wordCounts = df.groupBy("value").count();

        // Output the results to the console
        wordCounts.writeStream()
            .outputMode("complete")
            .format("console")
            .start()
            .awaitTermination();
    }
}
    </code></pre>

    <p>
        In these examples:
    </p>
    <ul>
        <li>The <strong>DStreams example</strong> demonstrates reading from a TCP source, performing a transformation, and printing the results.</li>
        <li>The <strong>Structured Streaming example</strong> demonstrates reading from a file source, performing a transformation, and writing the results to the console.</li>
    </ul>

    <p>
        Structured Streaming is generally preferred for new applications due to its higher-level API, improved fault tolerance, and advanced state management capabilities. DStreams remain useful for legacy systems and simpler stream processing tasks.
    </p>
</body>
</html>
