<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Advanced Spark MLlib Algorithms (Regression, Classification)</title>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        pre {
            background-color: #f4f4f4;
            border: 1px solid #ddd;
            padding: 10px;
            overflow-x: auto;
        }
        code {
            font-family: 'Courier New', monospace;
        }
    </style>
</head>
<body>
    <h1>Advanced Spark MLlib Algorithms (Regression, Classification)</h1>

    <p>
        Spark MLlib provides a variety of advanced machine learning algorithms for regression and classification tasks. These algorithms are designed to handle large-scale datasets and offer scalable solutions for predictive modeling. In this document, we will cover some of the advanced algorithms available in Spark MLlib for both regression and classification.
    </p>

    <h2>Advanced Regression Algorithms</h2>
    <ul>
        <li><strong>Linear Regression:</strong> Used for predicting a continuous target variable based on one or more predictor variables. Spark MLlib supports both simple and multiple linear regression.</li>
        <li><strong>Decision Tree Regressor:</strong> A decision tree-based method that splits data into subsets based on feature values to predict continuous outcomes.</li>
        <li><strong>Random Forest Regressor:</strong> An ensemble method that builds multiple decision trees and averages their predictions to improve accuracy and control overfitting.</li>
        <li><strong>Gradient-Boosted Trees Regressor:</strong> An ensemble technique that builds trees sequentially, each one correcting the errors of the previous one to improve prediction accuracy.</li>
    </ul>

    <h2>Advanced Classification Algorithms</h2>
    <ul>
        <li><strong>Logistic Regression:</strong> A widely used classification algorithm for binary and multiclass problems that estimates the probability of a binary outcome using a logistic function.</li>
        <li><strong>Decision Tree Classifier:</strong> Similar to the regressor, but used for classifying data into predefined classes based on feature values.</li>
        <li><strong>Random Forest Classifier:</strong> An ensemble method that combines multiple decision trees to make a classification decision, enhancing performance and robustness.</li>
        <li><strong>Gradient-Boosted Trees Classifier:</strong> A boosting method that improves classification performance by iteratively training weak classifiers and combining them into a strong classifier.</li>
    </ul>

    <h2>Example Source Code</h2>
    <p>
        Below are examples of how to use advanced regression and classification algorithms in Spark MLlib with Java.
    </p>

    <h3>Linear Regression Example</h3>
    <pre><code class="language-java">
import org.apache.spark.ml.Pipeline;
import org.apache.spark.ml.PipelineModel;
import org.apache.spark.ml.feature.VectorAssembler;
import org.apache.spark.ml.regression.LinearRegression;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;

public class LinearRegressionExample {
    public static void main(String[] args) {
        // Create a SparkSession
        SparkSession spark = SparkSession.builder()
            .appName("Linear Regression Example")
            .master("local[*]")
            .getOrCreate();

        // Load training data
        Dataset<Row> trainingData = spark.read().format("libsvm")
            .load("path/to/your/data.txt");

        // Create a VectorAssembler for feature columns
        VectorAssembler assembler = new VectorAssembler()
            .setInputCols(new String[]{"feature1", "feature2"})
            .setOutputCol("features");

        // Create a LinearRegression instance
        LinearRegression lr = new LinearRegression()
            .setFeaturesCol("features")
            .setLabelCol("label");

        // Create a Pipeline with the stages
        Pipeline pipeline = new Pipeline()
            .setStages(new org.apache.spark.ml.PipelineStage[]{assembler, lr});

        // Fit the model
        PipelineModel model = pipeline.fit(trainingData);

        // Make predictions
        Dataset<Row> predictions = model.transform(trainingData);
        predictions.select("features", "label", "prediction").show();

        // Stop the SparkSession
        spark.stop();
    }
}
    </code></pre>

    <h3>Random Forest Classifier Example</h3>
    <pre><code class="language-java">
import org.apache.spark.ml.Pipeline;
import org.apache.spark.ml.PipelineModel;
import org.apache.spark.ml.feature.VectorAssembler;
import org.apache.spark.ml.classification.RandomForestClassifier;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;

public class RandomForestClassifierExample {
    public static void main(String[] args) {
        // Create a SparkSession
        SparkSession spark = SparkSession.builder()
            .appName("Random Forest Classifier Example")
            .master("local[*]")
            .getOrCreate();

        // Load training data
        Dataset<Row> trainingData = spark.read().format("libsvm")
            .load("path/to/your/data.txt");

        // Create a VectorAssembler for feature columns
        VectorAssembler assembler = new VectorAssembler()
            .setInputCols(new String[]{"feature1", "feature2"})
            .setOutputCol("features");

        // Create a RandomForestClassifier instance
        RandomForestClassifier rf = new RandomForestClassifier()
            .setFeaturesCol("features")
            .setLabelCol("label");

        // Create a Pipeline with the stages
        Pipeline pipeline = new Pipeline()
            .setStages(new org.apache.spark.ml.PipelineStage[]{assembler, rf});

        // Fit the model
        PipelineModel model = pipeline.fit(trainingData);

        // Make predictions
        Dataset<Row> predictions = model.transform(trainingData);
        predictions.select("features", "label", "prediction").show();

        // Stop the SparkSession
        spark.stop();
    }
}
    </code></pre>

    <p>
        In these examples:
    </p>
    <ul>
        <li>A SparkSession is created to start the Spark application.</li>
        <li>Data is loaded from a LibSVM file format.</li>
        <li>A <code>VectorAssembler</code> is used to combine feature columns into a single feature vector.</li>
        <li>For linear regression, a <code>LinearRegression</code> model is created and fitted to the data.</li>
        <li>For classification, a <code>RandomForestClassifier</code> model is created and fitted to the data.</li>
        <li>The fitted model is used to make predictions, which are then displayed.</li>
    </ul>

    <p>
        These advanced algorithms in Spark MLlib help in building robust and scalable machine learning models for various regression and classification tasks.
    </p>
</body>
</html>
