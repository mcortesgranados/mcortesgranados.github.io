<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Integration of Spark with NoSQL Databases (Cassandra, HBase)</title>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        pre {
            background-color: #f4f4f4;
            border: 1px solid #ddd;
            padding: 10px;
            overflow-x: auto;
        }
        code {
            font-family: 'Courier New', monospace;
        }
    </style>
</head>
<body>
    <h1>Integration of Spark with NoSQL Databases (Cassandra, HBase)</h1>

    <p>
        Apache Spark provides powerful capabilities for integrating with NoSQL databases such as Cassandra and HBase. These integrations enable Spark to perform distributed data processing and analytics on data stored in NoSQL databases. Below, we provide an overview of how to connect Spark with Cassandra and HBase, along with example source code for each.
    </p>

    <h2>Integration with Cassandra</h2>
    <ul>
        <li><strong>Introduction:</strong> Apache Cassandra is a distributed NoSQL database designed for high availability and scalability. Spark provides a connector for Cassandra, allowing you to read from and write to Cassandra tables efficiently.</li>
        <li><strong>Connector:</strong> The Spark-Cassandra connector provides integration capabilities. To use it, you need to include the connector dependency in your project.</li>
        <li><strong>Configuration:</strong> Configure the Spark session with Cassandra connection details, such as the Cassandra host, port, and keyspace.</li>
    </ul>

    <h2>Example Source Code for Cassandra</h2>
    <pre><code class="language-java">
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;

public class CassandraIntegrationExample {
    public static void main(String[] args) {
        // Create a SparkSession with Cassandra configuration
        SparkSession spark = SparkSession.builder()
            .appName("Cassandra Integration Example")
            .master("local[*]")
            .config("spark.cassandra.connection.host", "127.0.0.1") // Cassandra host
            .getOrCreate();

        // Read data from Cassandra
        Dataset<Row> df = spark.read()
            .format("org.apache.spark.sql.cassandra")
            .option("keyspace", "my_keyspace")
            .option("table", "my_table")
            .load();

        // Show results
        df.show();

        // Write data to Cassandra
        df.write()
            .format("org.apache.spark.sql.cassandra")
            .option("keyspace", "my_keyspace")
            .option("table", "my_table")
            .save();

        // Stop the SparkSession
        spark.stop();
    }
}
    </code></pre>

    <h2>Integration with HBase</h2>
    <ul>
        <li><strong>Introduction:</strong> Apache HBase is a distributed, scalable NoSQL database designed for large-scale data storage and retrieval. Spark provides integration with HBase for efficient data processing.</li>
        <li><strong>Connector:</strong> The Spark-HBase connector enables Spark to interact with HBase tables. You need to include the HBase connector dependency in your project.</li>
        <li><strong>Configuration:</strong> Configure the Spark session with HBase connection details, such as HBase Zookeeper quorum and HBase table names.</li>
    </ul>

    <h2>Example Source Code for HBase</h2>
    <pre><code class="language-java">
import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.client.Connection;
import org.apache.hadoop.hbase.client.ConnectionFactory;
import org.apache.hadoop.hbase.client.Table;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.execution.datasources.hbase.HBaseTableCatalog;

public class HBaseIntegrationExample {
    public static void main(String[] args) {
        // Create a SparkSession with HBase configuration
        SparkSession spark = SparkSession.builder()
            .appName("HBase Integration Example")
            .master("local[*]")
            .getOrCreate();

        // HBase configuration
        String catalog = "{\"table\":{\"namespace\":\"default\", \"name\":\"my_table\"}, \"rowkey\":\"key\", \"columns\":{\"key\":{\"cf\":\"rowkey\", \"col\":\"key\", \"type\":\"string\"}, \"data\":{\"cf\":\"cf\", \"col\":\"data\", \"type\":\"string\"}}}";

        // Read data from HBase
        Dataset<Row> df = spark.read()
            .format("org.apache.spark.sql.execution.datasources.hbase.HBaseTableCatalog")
            .option(HBaseTableCatalog.tableCatalog(), catalog)
            .load();

        // Show results
        df.show();

        // Write data to HBase
        df.write()
            .format("org.apache.spark.sql.execution.datasources.hbase.HBaseTableCatalog")
            .option(HBaseTableCatalog.tableCatalog(), catalog)
            .save();

        // Stop the SparkSession
        spark.stop();
    }
}
    </code></pre>

    <p>
        In these examples:
    </p>
    <ul>
        <li><strong>Cassandra Integration Example:</strong> Demonstrates how to read from and write to Cassandra using the Spark-Cassandra connector. Configuration includes specifying the Cassandra host and using the connector to interact with Cassandra tables.</li>
        <li><strong>HBase Integration Example:</strong> Shows how to read from and write to HBase using the Spark-HBase connector. Configuration involves setting up the HBase catalog and specifying the HBase table and column mappings.</li>
    </ul>

    <p>
        Integrating Spark with NoSQL databases like Cassandra and HBase enables efficient data processing and analytics on large-scale, distributed data. By leveraging these integrations, you can take full advantage of Spark's powerful processing capabilities while working with NoSQL databases.
    </p>
</body>
</html>
