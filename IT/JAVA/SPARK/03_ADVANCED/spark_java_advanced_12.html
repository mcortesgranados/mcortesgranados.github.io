<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Advanced Window Functions in Spark SQL</title>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        pre {
            background-color: #f4f4f4;
            border: 1px solid #ddd;
            padding: 10px;
            overflow-x: auto;
        }
        code {
            font-family: 'Courier New', monospace;
        }
    </style>
</head>
<body>
    <h1>Advanced Window Functions in Spark SQL</h1>

    <p>
        Window functions in Spark SQL allow you to perform calculations across a set of table rows related to the current row. They are particularly useful for tasks that require comparing values within the same partition of data. Advanced window functions can help with complex analytics, such as ranking, cumulative sums, and moving averages.
    </p>

    <h2>Key Window Functions</h2>
    <ul>
        <li><strong>ROW_NUMBER:</strong> Assigns a unique number to each row within a partition of a result set. Useful for ranking rows.</li>
        <li><strong>DENSE_RANK:</strong> Assigns a rank to each row within a partition of a result set, with no gaps in ranking values.</li>
        <li><strong>NTILE:</strong> Divides the result set into a specified number of approximately equal parts and assigns a unique integer to each part.</li>
        <li><strong>LEAD and LAG:</strong> Accesses data from subsequent or preceding rows within the same partition. Useful for calculating differences between rows.</li>
        <li><strong>SUM, AVG, MIN, MAX:</strong> Aggregate functions that can be used with window specifications to calculate cumulative sums, averages, and other aggregate values over a window of rows.</li>
        <li><strong>FIRST_VALUE and LAST_VALUE:</strong> Retrieves the first or last value in a window partition.</li>
    </ul>

    <h2>Example Source Code</h2>
    <p>
        Below is an example of using advanced window functions in Spark SQL with Java. This example demonstrates ranking rows, calculating moving averages, and accessing preceding values.
    </p>

    <pre><code class="language-java">
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.expressions.Window;
import org.apache.spark.sql.functions;

public class WindowFunctionsExample {
    public static void main(String[] args) {
        // Create a SparkSession
        SparkSession spark = SparkSession.builder()
            .appName("Window Functions Example")
            .master("local[*]")
            .getOrCreate();

        // Create a DataFrame
        Dataset<Row> df = spark.createDataFrame(Arrays.asList(
            new Tuple2<>(1, "Alice", 1000),
            new Tuple2<>(2, "Bob", 1500),
            new Tuple2<>(3, "Charlie", 2000),
            new Tuple2<>(4, "David", 1200),
            new Tuple2<>(5, "Eva", 1700)
        ), Encoders.tuple(Encoders.INT(), Encoders.STRING(), Encoders.INT()).schema());

        // Define a window specification
        WindowSpec windowSpec = Window.orderBy("salary");

        // Apply ROW_NUMBER window function
        Dataset<Row> withRowNumber = df.withColumn("row_number", functions.row_number().over(windowSpec));

        // Apply DENSE_RANK window function
        Dataset<Row> withDenseRank = df.withColumn("dense_rank", functions.dense_rank().over(windowSpec));

        // Apply LEAD and LAG window functions
        WindowSpec leadLagSpec = Window.partitionBy("department").orderBy("salary");
        Dataset<Row> withLeadLag = df.withColumn("lead_salary", functions.lead("salary", 1).over(leadLagSpec))
                                      .withColumn("lag_salary", functions.lag("salary", 1).over(leadLagSpec));

        // Apply moving average
        WindowSpec movingAverageSpec = Window.orderBy("salary").rowsBetween(-2, 2);
        Dataset<Row> withMovingAvg = df.withColumn("moving_avg", functions.avg("salary").over(movingAverageSpec));

        // Show results
        withRowNumber.show();
        withDenseRank.show();
        withLeadLag.show();
        withMovingAvg.show();

        // Stop the SparkSession
        spark.stop();
    }
}
    </code></pre>

    <p>
        In this example:
    </p>
    <ul>
        <li>A <strong>SparkSession</strong> is created to start the Spark application.</li>
        <li>A DataFrame is created with sample data including IDs, names, and salaries.</li>
        <li>A window specification is defined to order rows by salary.</li>
        <li>ROW_NUMBER and DENSE_RANK functions are applied to rank the rows.</li>
        <li>LEAD and LAG functions are used to access subsequent and preceding salaries within partitions.</li>
        <li>A moving average is calculated over a window of rows centered around the current row.</li>
        <li>The results are displayed using <code>show()</code> method.</li>
    </ul>

    <p>
        Advanced window functions in Spark SQL allow for sophisticated data analysis and reporting by enabling complex calculations across rows within partitions. Understanding and using these functions effectively can help with a wide range of analytics tasks and improve the insights derived from your data.
    </p>
</body>
</html>
