<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Support Vector Machines (SVM) Example</title>
    <!-- Include necessary CSS or styling if needed -->
    <link href="../estilos.css" rel="stylesheet" type="text/css">
</head>
<body class="texto8_1">

<h1>Support Vector Machines (SVM) Example</h1>

<p>This is a simple example of Support Vector Machines (SVM) using Python and scikit-learn.</p>

<h2>Support Vector Machines Overview</h2>

<p>Support Vector Machines (SVM) is a powerful supervised learning algorithm used for classification and regression tasks. In the context of classification, SVM aims to find the hyperplane that best separates different classes in the feature space. The hyperplane is chosen to maximize the margin between the classes, and the data points on the margin are called support vectors.</p>

<p>Key concepts of Support Vector Machines:</p>

<ul>
    <li><b>Hyperplane:</b> The decision boundary that separates different classes.</li>
    <li><b>Margin:</b> The distance between the hyperplane and the nearest data points of each class.</li>
    <li><b>Support Vectors:</b> Data points on the margin that influence the position and orientation of the hyperplane.</li>
    <li><b>Kernel Trick:</b> Mapping data into a higher-dimensional space to make it linearly separable.</li>
</ul>

<p>SVM is effective in high-dimensional spaces and is particularly useful when the number of features is greater than the number of samples. Additionally, SVM can handle non-linear relationships between features through the use of different kernel functions.</p>

<p>Python Source Code:</p>

<pre><code># Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error

# Generate synthetic data
np.random.seed(42)
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100, 1)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the Support Vector Machines (SVM) model
model = SVR(kernel='linear')
model.fit(X_train, y_train.ravel())

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error: {mse}')

# Plot the results
plt.scatter(X_test, y_test, color='black')
plt.scatter(X_test, y_pred, color='red', marker='x')
plt.title('Support Vector Machines (SVM) Example')
plt.xlabel('X')
plt.ylabel('y')
plt.show()
</code></pre>

<p>Explanation:</p>

<ul>
    <li><b>Import Libraries:</b> Import necessary Python libraries, including NumPy for numerical operations, Matplotlib for plotting, and scikit-learn for machine learning.</li>
    <li><b>Generate Synthetic Data:</b> Create synthetic data with a linear relationship and some random noise (similar to the Linear Regression example).</li>
    <li><b>Split Data:</b> Split the data into training and testing sets using the <code>train_test_split</code> function.</li>
    <li><b>Train Model:</b> Create and train a Support Vector Machines (SVM) model using scikit-learn's <code>SVR</code>.</li>
    <li><b>Make Predictions:</b> Use the trained SVM model to make predictions on the test set.</li>
    <li><b>Evaluate Model:</b> Calculate Mean Squared Error to evaluate the performance of the model.</li>
    <li><b>Plot Results:</b> Plot the actual vs. predicted values for visualization.</li>
</ul>

<!-- Include necessary JavaScript libraries if needed -->

</body>
</html>
