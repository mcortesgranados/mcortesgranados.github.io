<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NLTK (Natural Language Toolkit)</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
            color: #000; /* Set text color to black */
        }

        h1, h2 {
            color: #000; /* Set heading color to black */
        }

        p {
            color: #000; /* Set paragraph text color to black */
        }

        ol {
            margin-bottom: 20px;
            color: #000; /* Set list text color to black */
        }

        pre {
            background-color: #f4f4f4;
            border: 1px solid #ddd;
            padding: 10px;
            overflow: auto;
            margin-bottom: 20px;
        }

        code {
            font-family: Monaco, monospace;
            font-size: 14px;
            color: #000; /* Set code text color to black */
        }
    </style>
</head>
<body>

<h1>NLTK (Natural Language Toolkit)</h1>

<p>NLTK is a powerful Python library for working with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources, such as WordNet. NLTK also includes a variety of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, among other natural language processing (NLP) tasks.</p>

<h2>Key Features and Components of NLTK:</h2>

<ol>
    <li><strong>Corpora and Resources:</strong> NLTK includes a collection of diverse corpora and lexical resources. These include text data for tasks such as part-of-speech tagging, named entity recognition, sentiment analysis, and more. The library also provides access to WordNet, which is a lexical database of the English language.</li>
    
    <li><strong>Tokenization:</strong> NLTK provides tools for tokenizing sentences and words. Tokenization is the process of breaking text into individual words or sentences.</li>
    
    <li><strong>Part-of-Speech Tagging:</strong> NLTK allows you to perform part-of-speech tagging, which involves assigning a grammatical category (such as noun, verb, adjective) to each word in a text.</li>
    
    <li><strong>Stemming and Lemmatization:</strong> NLTK includes tools for stemming (reducing words to their root form) and lemmatization (reducing words to their base or dictionary form).</li>
    
    <li><strong>Named Entity Recognition (NER):</strong> NLTK includes tools for identifying named entities (such as persons, organizations, locations) in text.</li>
    
    <li><strong>Frequency Distribution:</strong> NLTK provides tools for analyzing the frequency distribution of words in a text.</li>
</ol>

<h2>Example Code:</h2>

<pre>
<code>
import nltk
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk import pos_tag
from nltk.stem import PorterStemmer, WordNetLemmatizer
from nltk import ne_chunk
from nltk import FreqDist

# Tokenization
text = "NLTK is a powerful library for natural language processing."
words = word_tokenize(text)
sentences = sent_tokenize(text)

# Part-of-Speech Tagging
tagged_words = pos_tag(words)

# Stemming and Lemmatization
stemmer = PorterStemmer()
lemmatizer = WordNetLemmatizer()
stemmed_words = [stemmer.stem(word) for word in words]
lemmatized_words = [lemmatizer.lemmatize(word) for word in words]

# Named Entity Recognition
text_ner = "Barack Obama was born in Hawaii."
words_ner = word_tokenize(text_ner)
tagged_words_ner = pos_tag(words_ner)
named_entities = ne_chunk(tagged_words_ner)

# Frequency Distribution
freq_dist = FreqDist(words)

print("<strong>Tokenization:</strong>")
print("Words:", words)
print("Sentences:", sentences)

print("<strong>Part-of-Speech Tagging:</strong>")
print("Tagged Words:", tagged_words)

print("<strong>Stemming and Lemmatization:</strong>")
print("Stemmed Words:", stemmed_words)
print("Lemmatized Words:", lemmatized_words)

print("<strong>Named Entity Recognition (NER):</strong>")
print("Named Entities:", named_entities)

print("<strong>Frequency Distribution:</strong>")
print("Most Common Words:", freq_dist.most_common(5))
</code>
</pre>

<p>To use NLTK, you'll need to install it first using:</p>

<pre>
<code>
pip install nltk
</code>
</pre>

<p>After installation, you may need to download additional resources such as corpora and models. NLTK provides a convenient way to download these resources using the <code>nltk.download
